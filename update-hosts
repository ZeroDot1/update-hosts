#!/bin/sh

#
#  The MIT License (MIT)
#
#  Copyright (c) 2015 - 2016 Peter Kenji Yamanaka
#  Copyright (c) 2015 Héctor Molinero Fernández
#
#  Permission is hereby granted, free of charge, to any person obtaining a copy
#  of this software and associated documentation files (the "Software"), to deal
#  in the Software without restriction, including without limitation the rights
#  to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
#  copies of the Software, and to permit persons to whom the Software is
#  furnished to do so, subject to the following conditions:
#
#  The above copyright notice and this permission notice shall be included in all
#  copies or substantial portions of the Software.
#
#  THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
#  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
#  FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
#  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
#  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
#  OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
#  SOFTWARE.

# Author:
#  Héctor Molinero Fernández <me@znt.se>.
#
# Modified by:
#  pyamsoft <pyam(dot)soft(at)gmail(dot)com>

# For more information about these particular options, see
#    https://stackoverflow.com/questions/13468481/when-to-use-set-e
set -u

# Export the LC as the default C so that we do not run into locale based quirks
export LC_ALL=C

# Version
version="1.2.0"

# Configuration:
readonly sudolock="/tmp/update-hosts.sudolock"
readonly dst_ip="0.0.0.0"

temp_files=""
pids="" # Leave blank
blocklist="" # Leave this blank
hosts="" # Leave this blank

# Options
diff_file=0
remove_backups=0
display_pager=0
require_root=1

# NOTE: Adding the alias of the 0 domain to itself fixes a display issue that
#       can occur when using traceroute, netstat and the like.
header="
127.0.0.1 $(uname -n) localhost
255.255.255.255 broadcasthost
# Fixes a display anomaly in traceroute and netstat
0.0.0.0 0.0.0.0
"

# The base sources
# Provides a basic amount of protection without breaking sites, or breaking
# only a minimal amount of sites
readonly base_sources="
  http://winhelp2002.mvps.org/hosts.txt
  http://someonewhocares.org/hosts/hosts
  https://www.malwaredomainlist.com/hostslist/hosts.txt
  https://pgl.yoyo.org/adservers/serverlist.php?hostformat=hosts&mimetype=plaintext
  https://adaway.org/hosts.txt
  https://www.malwaredomainlist.com/hostslist/hosts.txt
  https://s3.amazonaws.com/lists.disconnect.me/simple_ad.txt
  https://s3.amazonaws.com/lists.disconnect.me/simple_malvertising.txt
  https://s3.amazonaws.com/lists.disconnect.me/simple_malware.txt
  https://s3.amazonaws.com/lists.disconnect.me/simple_tracking.txt
  https://ransomwaretracker.abuse.ch/downloads/RW_DOMBL.txt
  https://zeustracker.abuse.ch/blocklist.php?download=domainblocklist
"

# Hosts-file.net server classifications
# Provides more in-depth protection and host blocking at the cost of
# breaking some sites
#
# readonly hosts_file_net_parts="
#   http://hosts-file.net/ad_servers.txt
#   http://hosts-file.net/emd.txt
#   http://hosts-file.net/exp.txt
#   http://hosts-file.net/fsa.txt
#   http://hosts-file.net/hjk.txt
#   http://hosts-file.net/mmt.txt
#   http://hosts-file.net/psh.txt
# "

# These entries are very large, and may break certain sites
# that rely on CDNs or third party sources
# Instead of downloading the entire hosts file and additional parts
# the split download above is recommended. The parts that you do not
# desire can be ignored individually instead of an all or nothing approach.
# The two sources below are generally not recommended nor needed. If you do
# wish to use them, be sure to comment out the above hosts-file.net entries
# or you will largely be pulling duplicate sources.
#
# readonly hosts_file_net_full="
#   http://hosts-file.net/download/hosts.txt
#   http://hosts-file.net/hphosts-partial.txt
# "


# The sources that will be parsed into the hosts file.
# By default only the sources in the ${base_sources} list
# are included, additional sources can be included by
# appending them onto lines following the base-sources line.
# Destinations and duplicate entries do not matter, as they will
# be sanitized and duplicates will be stripped out.
readonly sources="

  ${base_sources}

"

# Regex allowed
#  '\.com$'   -> all domains that end with '.com'
#  '^example' -> all domains that start with 'example'
#  '^sub.\example\.org$' -> literal domain 'sub.exmaple.org'

# Due to the binary yes or no nature of hosts file, all of the domains that
# relate in some way to the uBlock0 Unbreak list will be added here.
# This is to allow uBlock0 to block the specific parts of the domains, while
# not breaking other sites that actually rely on them
# Though not a great solution, this seems to be the only way to get around
# some sites breaking when blocking certain hosts
#
# Update 2016/03/15
readonly whitelist='
  google-analytics\.com$
  ^analytics\.google\.com$
  adf\.ly$
  ^widget-cdn\.rpxnow\.com$
  ^tags\.tiqcdn\.com$
  statcounter\.com$
  ^cdn-static\.liverail\.com$
  ^vox-static\.liverail\.com$
  ^s0\.2mdn\.net$
  ^cdn-i\.dmdentertainment\.com$
  ^cdn\.vurb\.com$
  ^target\.122\.2o7\.net$
  ^adm\.fwmrm\.net$
  mopub\.com$
  safelinking\.net$
  outbrain\.com$
  inc\.com$
  flurry\.com$
  ^c\.speedtest\.net$
  boldchat\.com$
  mixpanel\.com$
  ^charlie\.strim.io$
  ^ovh\.strim.io$
  cdn\.turner\.com$
  ^yui\.yahooapis\.com$
  ^top\.mail\.ru$
  ^css\.washingtonpost\.com$
  pcekspert\.com$
  clickbank\.com$
  yandex\.ru$
  yastatic\.net$
  carbonads\.net$
  ^imasdk\.googleapis\.com$
  2o7\.net$
  quantcast\.com$
  ^css5\.gaanacdn\.com$
  ^keen\.github\.io$
  ^cdn\.phoenix\.intergi\.com$
  kissmetrics\.com$
  viewpoint\.com$
  woopra\.com$
  monetate\.net$
  ^googleads\.g\.doubleclick\.net$
  ^img\.echohosting\.cafe24\.com$
  googletagmanager\.com$
  ^partner\.googleadservices\.com$
  pagefair\.com$
  ^ssl\.cdn-redfin\.com$
  ^www\.southwest\.com$
  marketwatch\.com$
  cloudfront\.net$
  nationalreview\.com$
  liveperson\.net$
  taboola\.com$
  ^ticketmaster\.122\.2o7\.net$
  phoronix\.com$
  ^files\.explosm\.net$
  ^cdn\.segment\.com$
  sorted\.org$
  ^\analytics\.edgekey\.net$
  tfag\.de$
  ^nav\.files\.bbci\.co\.uk$
  gamespot\.com$
  umbro\.com$
  ^shop\.puppetlabs\.com$
  flightradar24\.com$
  ^premium\.soundcloud\.com$
  ^stats\.bbc\.co\.uk$
'

# BLACKLIST DOMAINS
# Only exact strings, no regex supported
#    agor.io: Jumpscare
#    pinion.gg: Ads in Counter Strike: Global Offensive and other games
readonly blacklist='
  agor.io
  www.agor.io
  adback.pinion.gg
  api.pinion.gg
  bin.pinion.gg
  blog.pinion.gg
  bork.pinion.gg
  calendar.pinion.gg
  cdn.pinion.gg
  cp.pinion.gg
  crm.pinion.gg
  delivery.pinion.gg
  direct.pinion.gg
  docs.pinion.gg
  immuniser.pinion.gg
  kermit.pinion.gg
  legacy.pinion.gg
  log.pinion.gg
  mail.pinion.gg
  mailer.pinion.gg
  motd.pinion.gg
  ns1.pinion.gg
  ns2.pinion.gg
  ns3.pinion.gg
  ns4.pinion.gg
  ns5.pinion.gg
  ns6.pinion.gg
  office.pinion.gg
  oscar.pinion.gg
  pinion-log.pinion.gg
  pinion.gg
  pog.pinion.gg
  quartermaster.pinion.gg
  seen.pinion.gg
  stage.pinion.gg
  templ4d2.pinion.gg
  tix.pinion.gg
  transcoded.pinion.gg
  video.pinion.gg
  voip.pinion.gg
  wiki.pinion.gg
  www.pinion.gg
'

##
# Display a general message
##
action_msg()
{
  printf -- "%b + %b%s%b\n" "\033[1;33m" "\033[1;32m" "$1" "\033[0m"
}

##
# Display an error message
##
error_msg()
{
  printf -- "%b + %b%s%b\n" "\033[1;33m" "\033[1;31m" "$1" "\033[0m"
}

##
# Display an information snippet
##
info_msg()
{
  printf -- "   - %s\n" "$1"
}

##
# Check the environment path for the either wget or curl
# exit if it is not found
##
check_for_download_ability()
{
  if ! which curl > /dev/null 2>&1; then
    if ! which wget > /dev/null 2>&1; then
      printf -- "Either wget or curl are required for this script\n"
      printf -- "Please install either 'wget' or 'curl' onto your system.\n"
      exit 1
    fi
  fi
}

##
# Check the environment path for the given binary, exit if it is not found
##
check_for_binary()
{
  if ! which "$1" > /dev/null 2>&1; then
    printf -- "The '%s' binary is required for this script.\n" "$1"
    printf -- "Please install '%s' onto your system.\n" "$1"
    exit 1
  fi
}

##
# Print out the user configuration
##
print_config()
{
  info_msg "Hosts location: ${dst_hosts}"
  info_msg "Destination IP: ${dst_ip}"
}

##
# Decide what program to DL with
##
decide_dl_client()
{
  # Check for curl, if not found, use wget, as the check for either
  # Should have passed before this function
  local cmd=
  if which curl > /dev/null 2>&1; then
    cmd="curl -fsSL --connect-timeout 40 --max-time 60"
  else
    cmd="wget -T 10 -qO-"
  fi
  printf -- "%s" "${cmd}"
  unset cmd
}

##
# Sources list parsing
##
download_to_tempfile()
{
  # $1 cmd
  # $2 url
  # $3 tmpfile
  info_msg "Downloading from $2"
  local hostfile="$(printf -- "%s" "$($1 $2)")"
  if [ -z "${hostfile}" ]; then
    info_msg "  Failed to download from: $2"
    return
  fi

  # Guarantee an empty file
  printf -- "%s\n" "${hostfile}" > "$3"

  # Process each tmpfile seperately
  change_eol "$3" "$2"
  select_host_lines "$3" "$2"
  remove_untrusted_domain "$3" "$2"
  normalize_to_lowercase "$3" "$2"
  remove_local_entries "$3" "$2"
}

##
# Download the hosts file from each URL specified in source
# Download runs in parallel in the background
##
download_sources()
{
  # $1 cmd
  # local sources_size="${#sources[@]}"
  # for ((i=0; i<sources_size; i++)); do
  for src in ${sources}; do
    local current_temp_file=$(mktemp)
    temp_files="${current_temp_file} ${temp_files}"
    local url="${src}"
    download_to_tempfile "$1" "${url}" "${current_temp_file}" &
    unset url
    pids="${pids} $!"
  done

  # Wait for all parallel downloads to finish
  # Instead of taking a long time in total, this will only take as long
  # as it takes for the longest download to complete
  wait ${pids}

  # Write the contents of each download to the blocklist
  for hostfile in ${temp_files}; do
    local content="$(cat ${hostfile})"
    if [ ! -z "${content}" ]; then
      if [ -z "${blocklist}" ]; then
        blocklist=$(printf -- "%s\n" "${content}")
      else
        blocklist=$(printf -- "%s\n%s\n" "${blocklist}" "${content}")
      fi
    fi

    # Remove the temp file
    rm -f "${hostfile}"
    unset content
  done
}

##
# Change EOL from DOS to Unix format
##
change_eol()
{
  # $1 file
  # $2 url
  info_msg "Change EOL to Unix format: $2 ($1)"
  sed -r -i 's/$//' "$1"
}

##
# Only select lines which contain a host, do not select comments/other
##
select_host_lines()
{
  # $1 file
  # $2 url
  info_msg "Select only hosts lines: $2 ($1)"
  local ip_regex='([0-9]{1,3}\.){3}[0-9]{1,3}[[:blank:]]+'
  local domain_regex='([[:alnum:]_-]{1,63}\.)+[[:alpha:]][[:alnum:]_-]{1,62}'

  # KLUDGE
  # This leaves trailing comments in lines, making it not as effective
  # sed -n -i -r "/(^(${ip_regex})|^)${domain_regex}/p" "$1"
  #
  # This is an ugly workaround
  local content="$(grep -oE "(^(${ip_regex})|^)${domain_regex}" "$1")"
  printf -- "$content" > "$1"
  unset content
  unset ip_regex domain_regex
}

##
# Remove any predefined destinations, as they may be untrustworthy
##
remove_untrusted_domain()
{
  # $1 file
  # $2 url
  info_msg "Remove old destination: $2 ($1)"
  sed -i -r 's/^([0-9]{1,3}\.){3}[0-9]{1,3}[[:space:]]+//g' "$1"
}

##
# Normalize all entries to lowercase strings
##
normalize_to_lowercase()
{
  # $1 file
  # $2 url
  info_msg "Transform all entries to lowercase: $2 ($1)"

  # KLUDGE
  # Awk for some reason stops parsing after 1024 lines
  # awk -v tf="$1" '{print tolower($0) > tf}' "$1"
  #
  # This is an ugly work around
  local content="$(awk '{print tolower($0)}' "$1")"
  printf -- "${content}" > "$1"
  unset content
}

##
# Remove any entries containing the localhost, as it will be added by
# the header later on
##
remove_local_entries()
{
  # $1 file
  # $2 url
  info_msg "Remove local entries: $2 ($1)"
  sed -n -i -r \
    '/^(localhost|localhost.localdomain|local|broadcasthost)$/!p' "$1"
}

##
# Apply the user whitelist
##
apply_whitelist()
{
  info_msg "Apply whitelist"
  if [ -z "${blocklist}" ]; then
    return 1
  fi

  for domain in ${whitelist}; do
    blocklist=$(printf -- "%s\n" "${blocklist}" | sed -r "/${domain}/d")
  done
}

##
# Apply the user blacklist
##
apply_blacklist()
{
  info_msg "Apply blacklist"
  # Cache the blacklist domains so that the entire block list
  # does not have to be echoed each time.
  # Fix an issue which adds a rogue newline into the blacklist,
  # creating an blank entry in the hosts file of
  # 0.0.0.0 <space>

  # Domains initialized as first blacklist entry
  local domains=""
  for domain in ${blacklist}; do
    if [ -z "${domains}" ]; then
      domains="${domain}"
    else
      domains=$(printf -- "%s\n%s\n" "${domains}" "${domain}")
    fi
  done

  if [ -z "${blocklist}" ]; then
    blocklist=$(printf -- "%s\n" "${domains}")
  else
    blocklist=$(printf -- "%s\n%s\n" "${blocklist}" "${domains}")
  fi
  unset domains
}

##
# Remove duplicate entries
##
remove_duplicates()
{
  info_msg "Remove duplicate entries"
  blocklist=$(printf -- "%s\n" "${blocklist}" | awk '!a[$0]++')
}

##
# Sort the entries by string numerical value
##
sort_entries()
{
  info_msg "Sort entries"
  blocklist=$(printf -- "%s\n" "${blocklist}" | sort -n)
}

##
# Add the configured destination, by default the zero address
##
add_new_destination()
{
  info_msg "Add new destination"
  blocklist=$(printf -- "%s\n" "${blocklist}" | sed "s/^/${dst_ip} /g")
}

##
# Parse the header and create the new hosts file
##
generate_new_hosts_file()
{
  header=$(printf -- "# <header>%s# </header>\n" "${header}")
  header=$(printf -- "# %s\n%s\n" "$(date)" "${header}")
  hosts=$(printf -- "%s\n# <blocklist>\n%s\n# </blocklist>" \
    "${header}" "${blocklist}")
}

##
# Backup original hosts file
##
backup_old_hosts_file()
{
  if [ -f "${dst_hosts}" ]; then
    info_msg "Creating backup of original hosts file..."
    if [ "$(id -u)" -ne 0 ] && [ "${require_root}" -eq 1 ]; then
      sudo cp "${dst_hosts}" "${dst_backup}" || {
      error_msg "Failed to copy to file ${dst_backup}"
      exit 4
    }
    else
      cp "${dst_hosts}" "${dst_backup}" || {
      error_msg "Failed to copy to file ${dst_backup}"
      exit 4
    }
    fi
  else
    info_msg "No original file exists to create backup"
  fi
}

##
# Install the new hosts file to the destination
##
install_new_hosts_file()
{
  info_msg "Installing new hosts file..."
  if [ "$(id -u)" -ne 0 ] && [ "${require_root}" -eq 1 ]; then
    printf -- "%s\n" "${hosts}" | sudo tee "${dst_hosts}" > /dev/null || {
      error_msg "Failed to output to file ${dst_hosts}"
      exit 3
    }
  else
    printf -- "%s\n" "${hosts}" | tee "${dst_hosts}" > /dev/null || {
      error_msg "Failed to output to file ${dst_hosts}"
      exit 3
    }
  fi
}

##
# Fixes permission on file to 644
##
fix_file_permissons()
{
  if [ -f "$1" ]; then
    info_msg "Fixing permissions for file $1..."
    if [ "$(id -u)" -ne 0 ] && [ "${require_root}" -eq 1 ]; then
      sudo chmod 644 "$1" || {
        error_msg "Failed to chmod $1"
        exit 2
      }
    else
      chmod 644 "$1" || {
        error_msg "Failed to chmod $1"
        exit 2
      }
    fi
  else
    info_msg "Cannot fix permission for non-existant file $1"
  fi
}

##
# Print the differences between the number of hosts in each file
##
print_hosts_file_differences()
{
  local old_hosts_number
  if [ -f "${dst_backup}" ]; then
    old_hosts_number=$(wc -l < "${dst_backup}")
  else
    old_hosts_number=0
  fi
  local new_hosts_number=$(wc -l < "${dst_hosts}")
  printf -- "%b + %b%s %bhosts added! (%b + %b%s %b)\n" \
    "\033[1;33m" "\033[1;32m" "${new_hosts_number}" \
    "\033[0m" "\033[1;32m" "\033[1;34m" \
    "$((new_hosts_number - old_hosts_number))" "\033[0m"
  unset old_hosts_number new_hosts_number
}

remove_all_backup_hosts_files()
{
  for arg in /etc/hosts.backup.*; do
    info_msg "Removing backup file: ${arg}..."
    if [ "$(id -u)" -eq 0 ] && [ "${require_root}" -eq 1 ]; then
      rm -f "${arg}" > /dev/null 2>&1
    else
      sudo rm -f "${arg}" > /dev/null 2>&1
    fi
  done
}

print_file_diff()
{
  # Check for the DIFF environment variable
  # Conditional assignment works when using the set -u option
  : "${DIFF:=diff}"

  if [ -f "${dst_hosts}" ] && [ -f "${dst_backup}" ]; then

    # Using the pager requires extra binary
    check_for_binary "${DIFF}"
    action_msg "Displaying diff of ${dst_backup} and "${dst_hosts} using "${DIFF}"

    "${DIFF}" -u "${dst_backup}" "${dst_hosts}"
  else
    error_msg "Cannot diff ${dst_backup} and ${dst_hosts} using ${DIFF}"
  fi
}

display_hosts_in_pager()
{
  # Check for the PAGER environment variable
  # Conditional assignment works when using the set -u option
  : "${PAGER:=less}"

  if [ -f "${dst_hosts}" ]; then

    # Using the pager requires extra binary
    check_for_binary "${PAGER}"
    action_msg "Displaying ${dst_hosts} in ${PAGER}..."

    "${PAGER}" "${dst_hosts}"
  else
    error_msg "File ${dst_hosts} does not exist. Cannot output to ${PAGER}"
  fi
}

sudoloop()
{
  touch "${sudolock}"
  while [ -e "${sudolock}" ]; do
    sudo -n -v
    sleep 2
  done
}

cancel_sudoloop()
{
  [ -e "${sudolock}" ] && rm -f "${sudolock}"

  # Kill runaway pids
  for p in ${pids}; do
    kill "${p}" > /dev/null 2>&1
  done

  # rm leftover files
  for temp in ${temp_files}; do
    rm -f "${temp}" > /dev/null 2>&1
  done

  exit 0
}

print_version()
{
  printf -- "update-hosts[${version}]\n"
  echo
}


# Script begins here
dst_hosts="/etc/hosts"

# Check for required binaries, exit out if they are not present
check_for_download_ability
check_for_binary sed
check_for_binary grep
check_for_binary sort
check_for_binary touch
check_for_binary sleep
check_for_binary rm
check_for_binary awk
check_for_binary tee
check_for_binary cp
check_for_binary wc
check_for_binary printf
check_for_binary chmod
check_for_binary mktemp
check_for_binary cat

# Handle options
# Options
#   -h | --help     Display help
#   -v | --version  Display version
#   -r | --remove   Remove backups
#   -p | --pager    Display hosts file in pager
#   -o | --output   The file to output to
#   -n | --noroot   Do not require root to output.
for arg in $@; do
  case "${arg}" in
    "-h"|"--help")
      print_version
      printf -- "  Options:\n"
      printf -- "     -h | --help     Display help\n"
      printf -- "     -v | --version  Display version\n"
      printf -- "     -r | --remove   Remove backups\n"
      printf -- "     -p | --pager    Display hosts file in pager\n"
      printf -- "     -o | --output   The file to output to\n"
      printf -- "     -n | --noroot   Do not require root to output\n"
      printf -- "     -d | --diff     Display a diff of the output file\n"
      exit 0
      ;;
    "-v"|"--version")
      print_version
      exit 0
      ;;
    "-r"|"--remove")
      remove_backups=1
      shift
      ;;
    "-p"|"--pager")
      display_pager=1
      shift;
      ;;
    "-o"|"--output")
      shift
      if [ $# -ge 1 ]; then
        if  [ -z "$1" ]; then
          printf -- "Must specify an output file.\n"
          exit 1
        else
          dst_hosts="$1"
          shift
        fi
      else
        printf -- "Must specify an output file.\n"
        exit 1
      fi
      ;;
    "-n"|"--noroot")
      require_root=0
      shift
      ;;
    "-d"|"--diff")
      diff_file=1;
      shift
      ;;
  esac
done

readonly dst_backup="${dst_hosts}.backup.$(date +%Y%m%d)"

# Check if pager is set
# TODO Add support for a $PAGER variable
if [ "${display_pager}" -eq 1 ]; then
  display_hosts_in_pager

  action_msg "Exiting..."
  # Clean exit
  exit 0
fi

# Trap exit signals
trap cancel_sudoloop INT

if [ "$(id -u)" -ne 0 ] && [ "${require_root}" -eq 1 ]; then
  check_for_binary sudo

  # initialize sudo
  sudo -v || exit 1

  # Start sudoloop
  sudoloop &
fi

# Process begins:
action_msg "Configuration:"
print_config

action_msg "Downloading sources lists..."
download_sources "$(decide_dl_client)"

action_msg "Generating hosts file..."
apply_whitelist
apply_blacklist
remove_duplicates
sort_entries
add_new_destination
generate_new_hosts_file
backup_old_hosts_file
install_new_hosts_file
fix_file_permissons "${dst_hosts}"
fix_file_permissons "${dst_backup}"
print_hosts_file_differences
if [ "${diff_file}" -eq 1 ]; then
  print_file_diff "${dst_backup}" "${dst_hosts}"
fi

# Cleanup
if [ "${remove_backups}" -eq 1 ]; then
  remove_all_backup_hosts_files
fi
cancel_sudoloop

# vim: set syntax=sh tabstop=2 softtabstop=2 shiftwidth=2 shiftround expandtab:

